{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_KNN_Amazon_fine_food_reviews.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "UQjICOte2ZLH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Excercise_3 : K-NN on Amazon Fine Food Review Dataset.\n",
        "\n",
        "****Objective: ****\n",
        "  To find accuracy of the K-NN model using 10-fold cross_validation(brute,kd_tree) on the amazon_fine_food_review dataset.\n",
        "  \n",
        "  **Steps:**\n",
        "  1. Imprort libraries and datset.\n",
        "  2. Perform datacleaning , Text preprocessing(removing html-tags,special_characters,convert words to lower case, remove stopwords,remove words len < 2,stemming(Snowball)).\n",
        "  3. Apply text-to-vector techniques like Bag-of-words,Tf-idf,Average Word2Vec, Tfidf weighted Word2Vec.\n",
        "  4. For Each Technique find the best accuracy using 10-fold cross_validation with brute and kdtree algorithms."
      ]
    },
    {
      "metadata": {
        "id": "PIb1Wu906SKj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WWTSxkyu2M1G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sqlite3\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.cross_validation import cross_val_score\n",
        "from sklearn.cross_validation import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from gensim.models import Word2Vec\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lSlbZ2rO7h9y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rzivneyv4jFM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import Data"
      ]
    },
    {
      "metadata": {
        "id": "Aelq6nsB4hP8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# using the SQLite Table to read data.\n",
        "con = sqlite3.connect('/content/drive/My Drive/Colab Notebooks/database.sqlite') \n",
        "\n",
        "#filtering only positive and negative reviews i.e. \n",
        "# not taking into consideration those reviews with Score=3\n",
        "filtered_data = pd.read_sql_query(\"\"\" SELECT * FROM Reviews WHERE Score != 3 \"\"\", con,coerce_float=True) \n",
        "\n",
        "\n",
        "# Give reviews with Score>3 a positive rating, and reviews with a score<3 a negative rating.\n",
        "def partition(x):\n",
        "    if x < 3:\n",
        "        return 0\n",
        "    return 1\n",
        "\n",
        "#changing reviews with score less than 3 to be positive and vice-versa\n",
        "actualScore = filtered_data['Score']\n",
        "positiveNegative = actualScore.map(partition) \n",
        "filtered_data['Score'] = positiveNegative\n",
        "print(\"Number of data points in our data\", filtered_data.shape)\n",
        "filtered_data.head(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bgOa_j644vzJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# DataCleaning"
      ]
    },
    {
      "metadata": {
        "id": "ssTndxP14uqG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Sorting data according to ProductId in ascending order,default_axis = 0,na_position-default-last.\n",
        "sorted_data = filtered_data.sort_values('ProductId', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
        "#Deduplication of entries\n",
        "final=sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\n",
        "final=final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N5mMKmm05Al1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Text-Preprocessing.\n",
        "1. Remove html-tags.\n",
        "2. Remove punctuations and special characters.\n",
        "3. remove non-alpha numeric charcters and words with length less than 2.\n",
        "4. Convert words to lowercase.\n",
        "5. Remove stopwords.\n",
        "6. Apply stemming(Snowball Stemming)"
      ]
    },
    {
      "metadata": {
        "id": "ZLoYWWfd4uWN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stop = set(stopwords.words('english')) #set of stopwords\n",
        "sno = nltk.stem.SnowballStemmer('english') #initialising the snowball stemmer\n",
        "#function to clean the word of any html-tags\n",
        "def cleanhtml(sentence): \n",
        "    cleanr = re.compile('<.*?>') #compiles a pattern.\n",
        "    cleantext = re.sub(cleanr, ' ', sentence) #replaces cleanr with '' in sentence.\n",
        "    return cleantext\n",
        "#function to clean the word of any punctuation or special characters\n",
        "def cleanpunc(sentence): \n",
        "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
        "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
        "    return  cleaned\n",
        "  \n",
        "if not os.path.isfile('/content/drive/My Drive/Colab Notebooks/final.sqlite'):\n",
        "    i=0\n",
        "    str1=' '\n",
        "    final_string=[]\n",
        "    s=''\n",
        "    for sent in tqdm(final['Text'].values):\n",
        "        filtered_sentence=[]\n",
        "        sent=cleanhtml(sent) # remove HTMl tags\n",
        "        for w in sent.split():\n",
        "            for cleaned_words in cleanpunc(w).split():\n",
        "                if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):    \n",
        "                    if(cleaned_words.lower() not in stop):\n",
        "                        s=(sno.stem(cleaned_words.lower())).encode('utf8')\n",
        "                        filtered_sentence.append(s)\n",
        "                    else:\n",
        "                        continue\n",
        "                else:\n",
        "                    continue \n",
        "        str1 = b\" \".join(filtered_sentence) #final string of cleaned words\n",
        "        final_string.append(str1)\n",
        "        i+=1\n",
        "\n",
        "    final['CleanedText']=final_string #adding a column of CleanedText which displays the data after pre-processing of the review \n",
        "    final['CleanedText']=final['CleanedText'].str.decode(\"utf-8\")\n",
        "        # store final table into an SQlLite table for future.\n",
        "    conn = sqlite3.connect('/content/drive/My Drive/Colab Notebooks/final.sqlite')\n",
        "    c=conn.cursor()\n",
        "    conn.text_factory = str\n",
        "    final.to_sql('Reviews', conn,  schema=None, if_exists='replace',index=True, index_label=None, chunksize=None, dtype=None)\n",
        "    conn.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vMoUxr4J2M3A",
        "colab_type": "code",
        "outputId": "d331d733-dd07-43ee-c8cd-bccb99fa6284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "# importing the preprocessed dataset\n",
        "\n",
        "con = sqlite3.connect('/content/drive/My Drive/Colab Notebooks/final.sqlite')\n",
        "final = pd.read_sql_query(\"\"\"SELECT * FROM Reviews WHERE Score != 3\"\"\",con)\n",
        "#random sampling \n",
        "\n",
        "#Sort the datset by timstamp.\n",
        "final.sort_values(by=['Time'],ascending=True,inplace=True,na_position='first')\n",
        "df = final[0:100000]\n",
        "df['Score'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    87729\n",
              "0    12271\n",
              "Name: Score, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "tMPbC1Rv6A9O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Observations:** \n",
        "1. Imbalanced sample."
      ]
    },
    {
      "metadata": {
        "id": "UBvC1Lzp2M6d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Function to apply K-NN 10-fold cross validation on the dataset using brute-force and kd-tree algorithms**"
      ]
    },
    {
      "metadata": {
        "id": "rNEayIr-2M6w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Function to apply 10-fold cross_validation using brute-force algorithm\n",
        "def brute_knn(x,y):\n",
        "    \n",
        "    cv_scores=[]\n",
        "    listo = list(range(0,20))\n",
        "    neighbors = list(filter(lambda x : x % 2 != 0,listo))\n",
        "    \n",
        "    for k in neighbors:\n",
        "    \n",
        "        knn = KNeighborsClassifier(n_neighbors=k,algorithm='brute',weights='distance')\n",
        "\n",
        "\n",
        "    optimal_k = neighbors[MSE.index(min(MSE))]\n",
        "    print('The optimal k value using brute-force is ',optimal_k)\n",
        "    optimal_knn = KNeighborsClassifier(n_neighbors=optimal_k,algorithm='brute',weights='distance')\n",
        "    optimal_knn.fit(x_train,y_train)\n",
        "\n",
        "    pred = optimal_knn.predict(x_test)\n",
        "\n",
        "    acc = accuracy_score(y_test,pred,normalize=True) * 100.0\n",
        "    \n",
        "    return acc\n",
        "\n",
        "#Function to apply 10-fold cross_validation using kd_tree algorithm\n",
        "\n",
        "def kdtree_knn(x,y):\n",
        "    \n",
        "    listp = list(range(0,20))\n",
        "    neighbors = list(filter(lambda x : x % 2 != 0,listp))\n",
        "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=0)\n",
        "\n",
        "    for k in neighbors:\n",
        "    \n",
        "        knn = KNeighborsClassifier(n_neighbors=k,algorithm='kd_tree',weights='distance')\n",
        "        cross_val = cross_val_score(knn,x_train,y_train,cv=10)\n",
        "        cv_scores.append(cross_val.mean())\n",
        "\n",
        "    MSE = [1 - x for x in cv_scores]\n",
        "\n",
        "    optimal_k = neighbors[MSE.index(min(MSE))]\n",
        "    print('The optimal k value using kd_tree is ',optimal_k)\n",
        "    optimal_knn = KNeighborsClassifier(n_neighbors=optimal_k,algorithm='kd_tree',weights='distance')\n",
        "    optimal_knn.fit(x_train,y_train)\n",
        "\n",
        "    pred = optimal_knn.predict(x_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test,pred,normalize=True) * 100.0\n",
        "    \n",
        "    return accuracy\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UDFL2TS1OTQo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Observations:**\n",
        "1. The dataset is split into 70:30,train and test data.\n",
        "1. 10-fold cross_validation is done using k values from 1 - 19 for both brute and kd_tree algorithms.\n",
        "2. Optimal k value is obtained and the knn model is tested on the test sample , \n",
        "      and accuracy score is obtained. \n"
      ]
    },
    {
      "metadata": {
        "id": "tJ1usyLk2M7j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# K-NN -  BOW"
      ]
    },
    {
      "metadata": {
        "id": "M8zN-Pel2M8P",
        "colab_type": "code",
        "outputId": "7a1728a7-ce6b-46e2-bb83-9d7dbc8f7d82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "bow = CountVectorizer()\n",
        "bow_matrix = bow.fit_transform(df['CleanedText']) \n",
        "standardized_data = StandardScaler(with_mean=False).fit_transform(bow_matrix)\n",
        "x_1=standardized_data.todense()\n",
        "y_1=df['Score']\n",
        "\n",
        "acc_b = brute_knn(x_1,y_1)\n",
        "acc_k = kdtree_knn(x_1,y_1)\n",
        "\n",
        "print('The accuracy using brute-force is ',acc_b)\n",
        "print('The accuracy using kd_tree is ',acc_k)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The optimal k value using brute-force is  3\n",
            "The optimal k value using kd_tree is  3\n",
            "The accuracy using brute-force is  85.33333333333334\n",
            "The accuracy using kd_tree is  85.33333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Heg09nD0S-Vn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Observations:**\n",
        "1. The optimal k value for both brute and kd_tree algorithms for this sample is 3.\n",
        "1. The accuracies of the model using both the brute-force and kd_tree algorithms for this sample are same."
      ]
    },
    {
      "metadata": {
        "id": "hLKgvXVr2M-8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# K-NN - TF-IDF"
      ]
    },
    {
      "metadata": {
        "id": "VBMIMWI42M_s",
        "colab_type": "code",
        "outputId": "7ab72d18-3fff-43b2-d43c-e434185f4255",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "tfidf_model = TfidfVectorizer(ngram_range=(1,2))\n",
        "tfidf_matrix = tfidf_model.fit_transform(df['CleanedText'])\n",
        "standardized_data = StandardScaler(with_mean=False).fit_transform(tfidf_matrix)\n",
        "x_2 = standardized_data.todense()\n",
        "y_2 = df['Score']\n",
        "\n",
        "acc_b = brute_knn(x_2,y_2)\n",
        "acc_k = kdtree_knn(x_2,y_2)\n",
        "print('The accuracy using brute-force is ',acc_b)\n",
        "print('The accuracy using kd_tree is ',acc_k)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The optimal k value using brute-force is  1\n",
            "The optimal k value using kd_tree is  1\n",
            "The accuracy using brute-force is  85.0\n",
            "The accuracy using kd_tree is  85.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aW7THFWbTjGC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Observations:**\n",
        "1.  The optimal k value for both brute-force and kd_tree is 1.\n",
        "2. The accuracies for both the algorithms for the sample is same."
      ]
    },
    {
      "metadata": {
        "id": "JJxIhNqp2NAs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# K-NN - AverageWord2Vec"
      ]
    },
    {
      "metadata": {
        "id": "pzofvlXO2NBW",
        "colab_type": "code",
        "outputId": "a6acd029-d303-4074-e3ac-190f27948518",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "#Average Word2Vector.\n",
        "list_of_sent=[]  #list of sentences of the cleanedtext.\n",
        "for sent in df['CleanedText'].values:\n",
        "    list_of_sent.append(sent.split())\n",
        "    \n",
        "w2v_model = Word2Vec(list_of_sent,min_count=5,size=50)\n",
        "w2v_words = list(w2v_model.wv.vocab)\n",
        "\n",
        "final_vec = [] #final list of vectors.\n",
        "\n",
        "for sent in list_of_sent:\n",
        "    sent_vec = np.zeros(50)\n",
        "    count = 0\n",
        "    for word in sent:\n",
        "        if word in w2v_words:\n",
        "            vec = w2v_model[word]\n",
        "            sent_vec += vec\n",
        "            count += 1\n",
        "    if count != 0:\n",
        "        sent_vec / count\n",
        "        \n",
        "    final_vec.append(sent_vec)\n",
        "\n",
        "standardized_data = StandardScaler().fit_transform(final_vec)\n",
        "x_3 = standardized_data\n",
        "y_3 = df['Score']\n",
        "\n",
        "acc_b = brute_knn(x_3,y_3)\n",
        "acc_k = kdtree_knn(x_3,y_3)\n",
        "\n",
        "print('The accuracy of the model using brute-force is',acc_b)\n",
        "print('The accuracy using kd_tree is ',acc_k)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The optimal k value using brute-force is  19\n",
            "The optimal k value using kd_tree is  19\n",
            "The accuracy of the model using brute-force is 84.66666666666667\n",
            "The accuracy using kd_tree is  84.66666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y3nhGdhITWG0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Observations:**\n",
        "1. The accuracies using both brute-force and kd_tree algorithms are same.\n"
      ]
    },
    {
      "metadata": {
        "id": "tgjcmG4x2NDe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# K-NN - TF-IDFweightedWord2Vec"
      ]
    },
    {
      "metadata": {
        "id": "mdeh8xvL2ND-",
        "colab_type": "code",
        "outputId": "22184278-8d6a-4e5b-bfa8-9d92f907b8b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "#Tfidf model.\n",
        "tfidf_model = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_model.fit_transform(df['CleanedText'])\n",
        "\n",
        "#create dictionary of idf of words.\n",
        "idf_values = dict(zip(tfidf_model.get_feature_names(),list(tfidf_model.idf_)))\n",
        "\n",
        "w2v_tfidf_vec = [] #final list of vectors.\n",
        "\n",
        "for sent in list_of_sent:\n",
        "    total_tfidf = 0\n",
        "    for word in sent:\n",
        "        if word in w2v_words:\n",
        "            vec = w2v_model[word]\n",
        "            tfidf = idf_values[word] * (sent.count(word)/ len(sent))\n",
        "            total_tfidf += tfidf\n",
        "            \n",
        "            sent_vec += vec * tfidf\n",
        "            \n",
        "    if total_tfidf != 0:\n",
        "        sent_vec / total_tfidf\n",
        "    w2v_tfidf_vec.append(sent_vec)\n",
        "    \n",
        "x_4 = StandardScaler().fit_transform(w2v_tfidf_vec)\n",
        "y_4 = df['Score']\n",
        "\n",
        "acc_b = brute_knn(x_4,y_4)\n",
        "acc_k = kdtree_knn(x_4,y_4)\n",
        "print(acc_b)\n",
        "print(acc_k)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The optimal k value using brute-force is  5\n",
            "The optimal k value using kd_tree is  3\n",
            "85.0\n",
            "85.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OAxYVYNa3Dqk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Observations:**\n",
        "1. The accuracies for both the algorithms are same."
      ]
    },
    {
      "metadata": {
        "id": "l3iho8Ndexnz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Conclusion:\n",
        "1. The 2000 samples taken was imbalanced, like the original dataset(35k,15k).\n",
        "1. The accuracy values for both brute-force and kd_tree algorithms are same for the  sample taken .\n"
      ]
    },
    {
      "metadata": {
        "id": "Gm6uqxHenaug",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}